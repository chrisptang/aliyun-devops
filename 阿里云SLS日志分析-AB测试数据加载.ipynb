{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "from alibabacloud_sls20201230.client import Client as Sls20201230Client\n",
    "from alibabacloud_tea_openapi import models as open_api_models\n",
    "from alibabacloud_sls20201230 import models as sls_20201230_models\n",
    "from alibabacloud_tea_util import models as util_models\n",
    "from alibabacloud_tea_util.client import Client as UtilClient\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import logging\n",
    "\n",
    "ds_to_run=datetime.now().strftime(\"%Y%m%d\")\n",
    "ds_yesterday=(datetime.now()-timedelta(days=1)).strftime(\"%Y%m%d\")\n",
    "\n",
    "# Configure the logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "ALIBABA_CLOUD_ACCESS_KEY_ID = os.environ[\"ALIBABA_CLOUD_ACCESS_KEY_ID\"]\n",
    "ALIBABA_CLOUD_ACCESS_KEY_SECRET = os.environ[\"ALIBABA_CLOUD_ACCESS_KEY_SECRET\"]\n",
    "\n",
    "config = open_api_models.Config(\n",
    "    access_key_id=ALIBABA_CLOUD_ACCESS_KEY_ID,\n",
    "    access_key_secret=ALIBABA_CLOUD_ACCESS_KEY_SECRET,\n",
    "    read_timeout=120 * 1000,\n",
    "    connect_timeout=10 * 1000,\n",
    "    no_proxy=\"cn-hangzhou.log.aliyuncs.com\",\n",
    ")\n",
    "# Endpoint 请参考 https://api.aliyun.com/product/Sls\n",
    "config.endpoint = f\"cn-hangzhou.log.aliyuncs.com\"\n",
    "sls_client = Sls20201230Client(config)\n",
    "sls_client._read_timeout = 120 * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取SLS日志的查询结果\n",
    "import time\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"user-agent\": \"AlibabaCloud API Workbench\",\n",
    "    \"x-log-apiversion\": \"0.6.0\",\n",
    "    \"x-log-bodyrawsize\": \"0\",\n",
    "    \"x-log-signaturemethod\": \"hmac-sha256\",\n",
    "    \"content-type\": \"application/json\",\n",
    "}\n",
    "\n",
    "\n",
    "def get_sls_data_by_query(\n",
    "    from_time: datetime,\n",
    "    to_time: datetime,\n",
    "    query: str = \"\",\n",
    "    project: str = \"xianmu-front-end-log\",\n",
    "    logstore: str = \"xm-mall\",\n",
    "    retry_time: int = 1,\n",
    "    line: int = 100,\n",
    "    offset: int = 0,\n",
    ") -> pd.DataFrame:\n",
    "    if retry_time < 0:\n",
    "        logging.error(f\"超过了最多重试次数\")\n",
    "        return None\n",
    "    if offset % 10000 == 0:\n",
    "        logging.info(\n",
    "            f\"即将获取数据: =====>from_time:{from_time}, to_time:{to_time}, logstore:{logstore}, query:{query[0:150]}\",\n",
    "        )\n",
    "\n",
    "    from_ = int(from_time.timestamp())\n",
    "    to_ = int(to_time.timestamp())\n",
    "\n",
    "    get_logs_v2headers = sls_20201230_models.GetLogsV2Headers(\n",
    "        common_headers=headers, accept_encoding=\"lz4\"\n",
    "    )\n",
    "    get_logs_v2request = sls_20201230_models.GetLogsV2Request(\n",
    "        from_=from_,\n",
    "        to=to_,\n",
    "        query=query,\n",
    "        line=line,\n",
    "        offset=offset,\n",
    "    )\n",
    "    runtime = util_models.RuntimeOptions(\n",
    "        connect_timeout=10 * 1000,\n",
    "        read_timeout=120 * 1000,\n",
    "        no_proxy=\"cn-hangzhou.log.aliyuncs.com\",\n",
    "        max_attempts=2,\n",
    "    )\n",
    "\n",
    "    product_view_data = []\n",
    "    try:\n",
    "        response = sls_client.get_logs_v2with_options(\n",
    "            project=project,\n",
    "            logstore=logstore,\n",
    "            request=get_logs_v2request,\n",
    "            headers=get_logs_v2headers,\n",
    "            runtime=runtime,\n",
    "        )\n",
    "        product_view_data = response.body.data\n",
    "        if offset % 10000 == 0:\n",
    "            logging.info(f\">=====数据条数:{len(product_view_data)}\")\n",
    "        return pd.DataFrame(product_view_data)\n",
    "    except Exception as error:\n",
    "        logging.error(\n",
    "            f\"查询SLS失败了,重试:{retry_time},project:{project},logstore:{logstore}, 错误:{error}\"\n",
    "        )\n",
    "        # 5 秒后重试一次\n",
    "        time.sleep(5)\n",
    "        return get_sls_data_by_query(\n",
    "            from_time=from_time,\n",
    "            to_time=to_time,\n",
    "            query=query,\n",
    "            project=project,\n",
    "            logstore=logstore,\n",
    "            retry_time=retry_time - 1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取SLS日志的查询结果\n",
    "# 获取用户的分桶信息\n",
    "\n",
    "\n",
    "def get_mid_variant_info(from_time: datetime, to_time: datetime):\n",
    "    user_ab_test_info_df = None\n",
    "    query = \"\"\"\n",
    "    ap:/abStrategy/userExperiments | select phone as cust_phone,uid as cust_id,\n",
    "        json_extract_scalar(json_extract_scalar(ai, '$.rt'),'$.data[\"new-home\"].variantId') variant_id,\n",
    "        json_extract_scalar(json_extract_scalar(ai, '$.rt'),'$.data[\"new-home\"].experimentId') experiment_id,\n",
    "        count(1) request_cnt,\n",
    "        date_format(min(__time__),'%Y-%m-%d %H:%i:%s') min_time,\n",
    "        date_format(max(__time__),'%Y-%m-%d %H:%i:%s') max_time\n",
    "    from log \n",
    "    where phone is not null and length(phone)>1 group by 1,2,3,4 \n",
    "    having variant_id is not null limit 1000000\n",
    "    \"\"\"\n",
    "\n",
    "    user_ab_test_info_df = get_sls_data_by_query(\n",
    "        from_time=from_time,\n",
    "        to_time=to_time,\n",
    "        query=query,\n",
    "    )\n",
    "    if user_ab_test_info_df is None:\n",
    "        logging.error(f\"没有获取到商品的曝光数据:{from_time}~{to_time}\")\n",
    "        return\n",
    "    \n",
    "    return user_ab_test_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取用户的点击信息（点击包括了商品详情页的点击、加入购物车的点击、以及立即购买的点击）\n",
    "\n",
    "\n",
    "def get_user_click_data(\n",
    "    from_time: datetime = datetime.now() - timedelta(hours=1),\n",
    "    to_time: datetime = datetime.now(),\n",
    "    page_name: str = \"/home\",\n",
    ") -> pd.DataFrame:\n",
    "    query = f\"\"\"type:cl and pageName:{page_name} and uid not null and sku |\n",
    "        select uid,bid,cid,pid,sku,pageName,url,date_format(__time__,'%Y-%m-%d %H:%i:%S') as arrive_time \n",
    "        from log where uid is not null limit 1000000\"\"\"\n",
    "    # user_click_df = pd.DataFrame()\n",
    "    # offset = 0\n",
    "\n",
    "    # while True:\n",
    "    batch_df = get_sls_data_by_query(\n",
    "        from_time=from_time, to_time=to_time, query=query\n",
    "        # , offset=offset\n",
    "    )\n",
    "\n",
    "    if batch_df is None or len(batch_df) == 0:\n",
    "        # if offset == 0:\n",
    "        #     logging.error(f\"没有获取到商品的曝光数据:{from_time}~{to_time}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 删除 'userAgent' 和 'v' 列\n",
    "    # batch_df = batch_df.drop(\n",
    "    #     columns=[\"userAgent\", \"useragent\", \"v\"], errors=\"ignore\"\n",
    "    # )\n",
    "\n",
    "    # 确保 uid 列不为 None、nan 或非数字，并将其转换为 int 类型\n",
    "    batch_df[\"uid\"] = pd.to_numeric(batch_df[\"uid\"], errors=\"coerce\")\n",
    "    batch_df[\"uid\"] = batch_df[\"uid\"].fillna(-1)\n",
    "    batch_df[\"uid\"] = batch_df[\"uid\"].astype(int)\n",
    "    # 删除任何仍然包含非数字的行\n",
    "    batch_df = batch_df[batch_df[\"uid\"] != -1]\n",
    "    return batch_df\n",
    "\n",
    "        # user_click_df = pd.concat([user_click_df, batch_df], ignore_index=True)\n",
    "\n",
    "        # if len(batch_df) < 100:\n",
    "        #     print(\n",
    "        #         f\"from_time:{from_time}, to_time:{to_time}, page_name:{page_name} 已经获取完毕了\"\n",
    "        #     )\n",
    "        #     break\n",
    "\n",
    "        # offset = len(user_click_df)\n",
    "        # if offset % 10000 == 0:\n",
    "        #     print(f\"获取更多数据, 新的offset:{offset}\")\n",
    "\n",
    "    # return user_click_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里是获取用户分桶数据并保存\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from odps_client import write_pandas_df_into_odps\n",
    "\n",
    "N = 2  # Number of days to loop over\n",
    "end_date = datetime.now().date()\n",
    "\n",
    "for i in range(N):\n",
    "    current_date = end_date - timedelta(days=i)\n",
    "    from_time = datetime.combine(current_date, datetime.min.time())\n",
    "    to_time = from_time + timedelta(hours=24)\n",
    "    ds = from_time.strftime(\"%Y%m%d\")\n",
    "\n",
    "    print(f\"Processing data for {from_time} to {to_time}, ds:{ds}\")\n",
    "\n",
    "    df = get_mid_variant_info(from_time=from_time, to_time=to_time)\n",
    "    df.drop(columns=[\"__source__\", \"__time__\"], inplace=True)\n",
    "\n",
    "    table_name = \"summerfarm_ds.temp_mall_new_home_ab_info_di\"\n",
    "\n",
    "    partition_spec = f\"ds={ds}\"\n",
    "    is_ok = write_pandas_df_into_odps(\n",
    "        df=df,\n",
    "        table_name=table_name,\n",
    "        partition_spec=partition_spec,\n",
    "        overwrite=True,\n",
    "    )\n",
    "\n",
    "    print(f\"save {len(df)} records into table:{table_name}, ds:{ds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里是获取用户点击数据并保存\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from odps_client import write_pandas_df_into_odps\n",
    "\n",
    "\n",
    "def get_csv_location_by_ds(ds: str) -> str:\n",
    "    return f\"./data/user_click_all_new_df_{ds}.csv\"\n",
    "\n",
    "\n",
    "# 如果CSV文件没有数据，则从get_user_click_data获取数据\n",
    "def load_user_click_data(ds_to_run: str) -> pd.DataFrame:\n",
    "    # 尝试从CSV文件读取数据\n",
    "    csv_file_path = get_csv_location_by_ds(ds_to_run)\n",
    "    if os.path.exists(csv_file_path):\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        if not df.empty:\n",
    "            print(f\"从CSV文件加载了{len(df)}条记录\")\n",
    "            return df\n",
    "\n",
    "    print(f\"未找到日期:{ds_to_run}的数据\")\n",
    "    return pd.DataFrame()\n",
    "\n",
    "\n",
    "start_date = datetime(2024, 9, 10).date()\n",
    "end_date = datetime.now().date()\n",
    "N = (end_date - start_date).days\n",
    "print(f\"start_date:{start_date}, end_date:{end_date}, N:{N}\")\n",
    "\n",
    "user_click_all_df = pd.DataFrame()\n",
    "\n",
    "for i in range(N):\n",
    "    from_time = datetime.combine(start_date + timedelta(i), datetime.min.time())\n",
    "    to_time = from_time + timedelta(hours=24)\n",
    "    ds = from_time.strftime(\"%Y%m%d\")\n",
    "    print(f\"正在处理 {from_time} 到 {to_time} 的数据，日期：{ds}\")\n",
    "\n",
    "    ds_click_df = load_user_click_data(ds)\n",
    "    if ds_click_df.empty:\n",
    "        for page_name in [\"/goods\", \"/search/goods\", \"/home\", \"/goods/category\"]:\n",
    "            print(\n",
    "                f\"正在处理 {from_time} 到 {to_time} 的数据，日期：{ds}, page_name:{page_name}\"\n",
    "            )\n",
    "            # 如果本地缓存没有，则重新跑一遍(每一个page都需要跑):\n",
    "            df = get_user_click_data(\n",
    "                from_time=from_time, to_time=to_time, page_name=page_name\n",
    "            )\n",
    "            df[\"ds\"] = ds\n",
    "            df.drop(columns=[\"__source__\", \"__time__\"], inplace=True, errors=\"ignore\")\n",
    "            ds_click_df = pd.concat([ds_click_df, df], ignore_index=True)\n",
    "\n",
    "        # 如果全部获取完了所有页面的数据，则写入本地缓存\n",
    "        # ds_click_df.drop_duplicates(\n",
    "        #     inplace=True,\n",
    "        #     subset=[\n",
    "        #         \"uid\",\n",
    "        #         \"cid\",\n",
    "        #         \"sid\",\n",
    "        #         \"pageName\",\n",
    "        #         \"__tag__:__receive_time__\",\n",
    "        #         \"__time_ns_part__\",\n",
    "        #     ],\n",
    "        # )\n",
    "        ds_click_df.to_csv(get_csv_location_by_ds(ds=ds), index=False)\n",
    "        print(\n",
    "            f\"已将 {len(ds_click_df)} 条记录保存到 user_click_all_df，总记录数：{len(user_click_all_df)}，日期：{ds}\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            f\"从本地缓存中获取到了DS:{ds}的数据,数据条数:{len(ds_click_df)}, pages:{list(ds_click_df['pageName'].unique())}\"\n",
    "        )\n",
    "    user_click_all_df = pd.concat([user_click_all_df, ds_click_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from odps_client import get_odps_sql_result_as_df\n",
    "\n",
    "user_view_sql=\"\"\"\n",
    "SELECT  ds\n",
    "        ,cust_id\n",
    "        ,b.variant_id\n",
    "        ,page_name\n",
    "        ,COUNT(1) as sku_view_cnt\n",
    "FROM    summerfarm_tech.dwd_log_mall_di a\n",
    "LEFT JOIN(\n",
    "        SELECT cust_id as mid,min(variant_id) variant_id\n",
    "        FROM summerfarm_ds.temp_mall_new_home_ab_info_di\n",
    "        WHERE ds>='20240910'\n",
    "        GROUP BY cust_id\n",
    ") b ON b.mid=a.cust_id\n",
    "WHERE   a.ds >= '20240910'\n",
    "AND     a.spu_id IS NOT NULL\n",
    "and     a.cust_id is not null\n",
    "AND     a.page_name in ('/goods','/search/goods','/home','/goods/category')\n",
    "group by a.ds\n",
    "        ,a.cust_id\n",
    "        ,b.variant_id\n",
    "        ,a.page_name\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "user_view_data_df=get_odps_sql_result_as_df(sql=user_view_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column '是否点开购物车卡片'\n",
    "user_click_all_df['是否点开购物车卡片'] = '否'\n",
    "user_click_all_df.loc[(user_click_all_df['bid'].str.contains('pid:唤起购买', na=False) | \n",
    "                       (user_click_all_df['pid'] == '唤起购买')), '是否点开购物车卡片'] = '是'\n",
    "\n",
    "user_click_all_df['是否点开商品详情页'] = '否'\n",
    "user_click_all_df.loc[user_click_all_df['bid'].str.contains('pid:goods,sku:', na=False), '是否点开商品详情页'] = '是'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_click_all_clean_df = user_click_all_df[\n",
    "    [\n",
    "        \"uid\",\n",
    "        \"ds\",\n",
    "        \"是否点开购物车卡片\",\n",
    "        \"是否点开商品详情页\",\n",
    "        \"pageName\",\n",
    "    ]\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandasql\n",
    "import pandasql.sqldf\n",
    "\n",
    "user_click_analytics_df = pandasql.sqldf(\"\"\"\n",
    "                                       select uid,ds,pageName\n",
    "                                        ,count(case when `是否点开商品详情页` = '是' then 1 end) as 点开商品详情页次数\n",
    "                                        ,count(case when `是否点开购物车卡片` = '是' then 1 end) as 点开购物车卡片次数\n",
    "                                       from user_click_all_clean_df\n",
    "                                       group by uid,ds,pageName\n",
    "                                       \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换连接键为相同类型（字符串）\n",
    "user_view_data_df[\"cust_id\"] = user_view_data_df[\"cust_id\"].fillna(-1)\n",
    "user_view_data_df[\"cust_id\"] = (\n",
    "    user_view_data_df[\"cust_id\"].astype(str).str.replace(\".0\", \"\", regex=False)\n",
    ")\n",
    "user_view_data_df[\"cust_id\"] = user_view_data_df[\"cust_id\"].astype(int)\n",
    "user_view_data_df[\"ds\"] = user_view_data_df[\"ds\"].astype(str)\n",
    "user_view_data_df[\"page_name\"] = user_view_data_df[\"page_name\"].astype(str)\n",
    "\n",
    "user_click_analytics_df = user_click_analytics_df[\n",
    "    user_click_analytics_df[\"uid\"] != \"nan\"\n",
    "]\n",
    "\n",
    "user_click_analytics_df[\"uid\"] = (\n",
    "    user_click_analytics_df[\"uid\"].astype(str).str.replace(\".0\", \"\", regex=False)\n",
    ")\n",
    "user_click_analytics_df[\"uid\"] = user_click_analytics_df[\"uid\"].astype(int)\n",
    "user_click_analytics_df[\"ds\"] = user_click_analytics_df[\"ds\"].astype(str)\n",
    "user_click_analytics_df[\"pageName\"] = user_click_analytics_df[\"pageName\"].astype(str)\n",
    "\n",
    "# 合并 user_view_data_df 和 user_click_analytics_df\n",
    "merged_df = user_view_data_df.merge(\n",
    "    user_click_analytics_df,\n",
    "    left_on=[\"cust_id\", \"ds\", \"page_name\"],\n",
    "    right_on=[\"uid\", \"ds\", \"pageName\"],\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_b\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['点开商品详情页次数']=merged_df['点开商品详情页次数'].fillna(0)\n",
    "merged_df['点开购物车卡片次数']=merged_df['点开购物车卡片次数'].fillna(0)\n",
    "merged_df['点开商品详情页次数']=merged_df['点开商品详情页次数'].astype(int)\n",
    "merged_df['点开购物车卡片次数']=merged_df['点开购物车卡片次数'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取用户加入购物车的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_add_cart_data(from_time: datetime, to_time: datetime) -> pd.DataFrame:\n",
    "    query = \"\"\"ap:/shopping/cart/upsert/insert and ai |select \n",
    "json_extract_scalar(json_extract_scalar(ai, '$.data'),'$.sku')sku,\n",
    "json_extract_scalar(json_extract_scalar(ai, '$.data'),'$.quantity')quantity,\n",
    "json_extract(json_extract_scalar(ai, '$.rt'), '$.status') return_status,\n",
    "json_extract_scalar(json_extract_scalar(ai, '$.rt'), '$.msg') return_msg,\n",
    "date_format(__time__, '%Y%m%d') as ds,\n",
    "uid,cid,sid,pageName,url,bid,ap \n",
    "from log limit 10000000\"\"\"\n",
    "\n",
    "    user_add_cart_df = None\n",
    "\n",
    "    user_add_cart_df = get_sls_data_by_query(\n",
    "        from_time=from_time,\n",
    "        to_time=to_time,\n",
    "        query=query,\n",
    "    )\n",
    "    if user_add_cart_df is None:\n",
    "        logging.error(f\"没有获取到用户的加入购物车数据:{from_time}~{to_time}\")\n",
    "        return\n",
    "\n",
    "    return user_add_cart_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里是获取用户加购物车数据并保存\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from odps_client import write_pandas_df_into_odps\n",
    "\n",
    "\n",
    "def get_add_cart_csv_location_by_ds(ds: str) -> str:\n",
    "    return f\"./data/user_add_cart_all_df_{ds}.csv\"\n",
    "\n",
    "\n",
    "# 如果CSV文件没有数据，则从get_user_click_data获取数据\n",
    "def load_user_add_cart_data(ds_to_run: str) -> pd.DataFrame:\n",
    "    # 尝试从CSV文件读取数据\n",
    "    csv_file_path = get_add_cart_csv_location_by_ds(ds_to_run)\n",
    "    if os.path.exists(csv_file_path):\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        if not df.empty:\n",
    "            print(f\"从CSV文件加载了{len(df)}条记录\")\n",
    "            return df\n",
    "\n",
    "    print(f\"未找到日期:{ds_to_run}的数据\")\n",
    "    return pd.DataFrame()\n",
    "\n",
    "\n",
    "start_date = datetime(2024, 9, 10).date()\n",
    "end_date = datetime.now().date()\n",
    "N = (end_date - start_date).days\n",
    "print(f\"start_date:{start_date}, end_date:{end_date}, N:{N}\")\n",
    "\n",
    "user_add_cart_all_df = pd.DataFrame()\n",
    "\n",
    "for i in range(N):\n",
    "    from_time = datetime.combine(start_date + timedelta(i), datetime.min.time())\n",
    "    to_time = from_time + timedelta(hours=24)\n",
    "    ds = from_time.strftime(\"%Y%m%d\")\n",
    "    print(f\"正在处理 {from_time} 到 {to_time} 的加购物车数据，日期：{ds}\")\n",
    "\n",
    "    ds_add_cart_df = load_user_add_cart_data(ds)\n",
    "    if ds_add_cart_df.empty:\n",
    "        # 如果本地缓存没有，则重新跑一遍\n",
    "        for hour_index in range(0, 24, 6):  # 6小时一批次\n",
    "            print(\n",
    "                f\"正在处理 {from_time} 到 {to_time} 的数据，日期：{ds}, hour_index:{hour_index}\"\n",
    "            )\n",
    "\n",
    "            from_hour = from_time + timedelta(hours=hour_index)\n",
    "            to_hour = from_hour + timedelta(hours=6)  # 6小时一个批次\n",
    "            print(f\"=======>from_hour:{from_hour}, to_hour:{to_hour}\")\n",
    "\n",
    "            df = get_user_add_cart_data(from_time=from_hour, to_time=to_hour)\n",
    "            ds_add_cart_df = pd.concat([ds_add_cart_df, df], ignore_index=True)\n",
    "\n",
    "        # 如果全部获取完了所有页面的数据，则写入本地缓存\n",
    "        ds_add_cart_df.drop_duplicates(\n",
    "            inplace=True,\n",
    "            subset=[\"uid\", \"cid\", \"sid\", \"pageName\", \"__time__\", \"sku\", \"quantity\"],\n",
    "        )\n",
    "        ds_add_cart_df.to_csv(get_add_cart_csv_location_by_ds(ds=ds), index=False)\n",
    "        print(\n",
    "            f\"已将 {len(ds_add_cart_df)} 条记录保存到 user_add_cart_all_df，总记录数：{len(user_add_cart_all_df)}，日期：{ds}\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            f\"从本地缓存中获取到了DS:{ds}的数据,数据条数:{len(ds_add_cart_df)}, pages:{list(ds_add_cart_df['pageName'].unique())}\"\n",
    "        )\n",
    "    user_add_cart_all_df = pd.concat(\n",
    "        [user_add_cart_all_df, ds_add_cart_df], ignore_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建加购物车汇总数据\n",
    "add_cart_summary_df = pandasql.sqldf(\"\"\"\n",
    "    SELECT uid, ds, pageName AS page_name,\n",
    "           COUNT(DISTINCT sku) AS added_sku_cnt,\n",
    "           SUM(quantity) AS added_quantity,\n",
    "           COUNT(1) AS add_cart_cnt \n",
    "    FROM user_add_cart_all_df \n",
    "    GROUP BY uid, ds, pageName\n",
    "\"\"\")\n",
    "\n",
    "# 转换uid类型为整数\n",
    "add_cart_summary_df['cust_id'] = add_cart_summary_df['uid'].astype(int)\n",
    "add_cart_summary_df['added_quantity'] = add_cart_summary_df['added_quantity'].astype(int)\n",
    "add_cart_summary_df['add_cart_cnt'] = add_cart_summary_df['add_cart_cnt'].astype(int)\n",
    "\n",
    "merged_df['ds']=merged_df['ds'].astype(str)\n",
    "add_cart_summary_df['ds']=add_cart_summary_df['ds'].astype(str)\n",
    "\n",
    "# 左连接merged_df和add_cart_summary_df\n",
    "merged_all_df = merged_df.merge(\n",
    "    add_cart_summary_df,\n",
    "    how='left',\n",
    "    on=['cust_id', 'ds', 'page_name']\n",
    ")\n",
    "\n",
    "# 显示合并后的数据前10行\n",
    "\n",
    "\n",
    "merged_all_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_static_df=pandasql.sqldf(f\"\"\"\n",
    "                  select variant_id\n",
    "                    ,count(distinct cust_id) 总用户数\n",
    "                    ,sum(sku_view_cnt) 用户SKU浏览数\n",
    "                    ,sum(点开商品详情页次数) 点开商品详情页次数\n",
    "                    ,sum(点开购物车卡片次数) 点开购物车卡片次数\n",
    "                    ,sum(add_cart_cnt) 加购成功次数API\n",
    "                    ,sum(added_quantity) SKU总加购件数\n",
    "                    ,round(sum(added_quantity)/count(distinct cust_id),2) 每用户加购SKU件数\n",
    "                    ,round(sum(点开购物车卡片次数) * 100.00/sum(sku_view_cnt),3) as 点击CTR_点开加购卡片\n",
    "                    ,round(sum(点开商品详情页次数) * 100.00/sum(sku_view_cnt),3) as 点击CTR_点到商品详情页\n",
    "                    ,round(sum(点开购物车卡片次数) * 100.00/sum(sku_view_cnt),3) as 点开加购卡片_转化率\n",
    "                    ,round(sum(add_cart_cnt) * 100.00/sum(sku_view_cnt),3) as 加购成功API_转化率\n",
    "                    ,min(ds)||'~'||max(ds) as 日期范围\n",
    "                  from merged_all_df\n",
    "                  where ds between '20240910' and '{ds_yesterday}'\n",
    "                  and page_name in('/search/goods','/goods','/goods/category','/home')\n",
    "                  group by variant_id\n",
    "                  \"\"\")\n",
    "\n",
    "click_static_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_df=pandasql.sqldf(\"\"\"\n",
    "                  select variant_id,page_name\n",
    "                    ,count(distinct cust_id) 总用户数\n",
    "                    ,sum(sku_view_cnt) 用户SKU浏览数\n",
    "                    ,sum(点开商品详情页次数) 点开商品详情页次数\n",
    "                    ,sum(点开购物车卡片次数) 点开购物车卡片次数\n",
    "                    ,sum(add_cart_cnt) 加购成功次数API\n",
    "                    ,sum(added_quantity) SKU总加购件数\n",
    "                    ,round(sum(added_quantity)/count(distinct cust_id),2) 每用户加购SKU件数\n",
    "                    ,round(sum(点开购物车卡片次数) * 100.00/sum(sku_view_cnt),3) as 点击CTR_点开加购卡片\n",
    "                    ,round(sum(点开商品详情页次数) * 100.00/sum(sku_view_cnt),3) as 点击CTR_点到商品详情页\n",
    "                    ,round(sum(点开购物车卡片次数) * 100.00/sum(sku_view_cnt),3) as 点开加购卡片_转化率\n",
    "                    ,round(sum(add_cart_cnt) * 100.00/sum(sku_view_cnt),3) as 加购成功API_转化率\n",
    "                    ,min(ds)||'~'||max(ds) as 日期范围\n",
    "                  from merged_all_df\n",
    "                  where ds>='20240910'\n",
    "                  and page_name in('/search/goods','/goods','/goods/category','/home')\n",
    "                  group by variant_id,page_name\n",
    "                    order by  page_name,variant_id\n",
    "                  \"\"\")\n",
    "\n",
    "page_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_to_end=datetime.now().strftime('%m%d')\n",
    "page_df.to_csv(f\"分页面的点击转化数据-0910-{ds_to_end}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_mall_new_home_ab_info_di_df=get_odps_sql_result_as_df(\"\"\"select ds,count(1) total_uv\n",
    "                                                           ,count(case when variant_id='V1' then 1 end) as v1_users\n",
    "                                                           ,count(case when variant_id='V2' then 1 end) as v2_users\n",
    "                                                           ,count(case when variant_id='V3' then 1 end) as v3_users\n",
    "                                                           ,count(case when variant_id='V4' then 1 end) as v4_users\n",
    "                                                           from summerfarm_ds.temp_mall_new_home_ab_info_di where ds >= '20240910' group by ds order by ds\"\"\")\n",
    "temp_mall_new_home_ab_info_di_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_by_yeaterday=(datetime.now()-timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "order_query=f\"\"\"\n",
    "SELECT  variant_id\n",
    "        ,COUNT(DISTINCT order_no) order_cnt\n",
    "        ,COUNT(DISTINCT m_id) 下单用户数\n",
    "        ,SUM(total_price) 总下单GMV\n",
    "        ,round(AVG(total_price),2) 订单均价\n",
    "        ,round(SUM(total_price)/COUNT(DISTINCT m_id),2) 用户平均GMV\n",
    "        ,MIN(order_time)||'~'||MAX(order_time) as time_range\n",
    "FROM    summerfarm_tech.ods_orders_df a\n",
    "LEFT JOIN   (\n",
    "                SELECT  cust_id\n",
    "                        ,MIN(variant_id) AS variant_id\n",
    "                FROM    summerfarm_ds.temp_mall_new_home_ab_info_di\n",
    "                WHERE   ds >= '20240910'\n",
    "                GROUP BY cust_id\n",
    "            ) variant\n",
    "ON      a.m_id = variant.cust_id\n",
    "AND     a.ds = MAX_PT(\"summerfarm_tech.ods_orders_df\")\n",
    "WHERE   a.order_time between '2024-09-10 00:00:00' and '{ds_by_yeaterday} 23:59:59'\n",
    "AND     a.ds = MAX_PT(\"summerfarm_tech.ods_orders_df\")\n",
    "AND     a.status in (2,3,6)\n",
    "GROUP BY variant_id;\n",
    "\"\"\"\n",
    "orders_df=get_odps_sql_result_as_df(order_query)\n",
    "orders_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_order_query=f\"\"\"\n",
    "SELECT  m_id as cust_id,variant_id\n",
    "        ,COUNT(DISTINCT order_no) order_cnt\n",
    "        ,SUM(total_price) 总下单GMV\n",
    "        ,round(AVG(total_price),2) 订单均价\n",
    "FROM    summerfarm_tech.ods_orders_df a\n",
    "LEFT JOIN   (\n",
    "                SELECT  cust_id\n",
    "                        ,MIN(variant_id) AS variant_id\n",
    "                FROM    summerfarm_ds.temp_mall_new_home_ab_info_di\n",
    "                WHERE   ds >= '20240910'\n",
    "                GROUP BY cust_id\n",
    "            ) variant\n",
    "ON      a.m_id = variant.cust_id\n",
    "AND     a.ds = MAX_PT(\"summerfarm_tech.ods_orders_df\")\n",
    "WHERE   a.order_time between '2024-09-10 00:00:00' and '{ds_by_yeaterday} 23:59:59'\n",
    "AND     a.ds = MAX_PT(\"summerfarm_tech.ods_orders_df\")\n",
    "AND     a.status in (2,3,6)\n",
    "GROUP BY variant_id,m_id;\n",
    "\"\"\"\n",
    "\n",
    "user_orders_df=get_odps_sql_result_as_df(user_order_query)\n",
    "user_orders_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 左连接orders_df到click_static_df\n",
    "order_merged_result = click_static_df.merge(orders_df, on=\"variant_id\", how=\"left\")\n",
    "\n",
    "# 重命名一些列名以避免冲突\n",
    "order_merged_result = order_merged_result.rename(\n",
    "    columns={\n",
    "        \"总用户数\": \"总浏览用户数\",\n",
    "        \"下单用户数\": \"总下单用户数\",\n",
    "        \"order_cnt\": \"总下单数\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# 选择需要的列并重新排序\n",
    "final_result = order_merged_result[\n",
    "    [\n",
    "        \"variant_id\",\n",
    "        \"总浏览用户数\",\n",
    "        \"用户SKU浏览数\",\n",
    "        \"点开商品详情页次数\",\n",
    "        \"点开购物车卡片次数\",\n",
    "        \"加购成功次数API\",\n",
    "        \"SKU总加购件数\",\n",
    "        \"每用户加购SKU件数\",\n",
    "        \"点击CTR_点开加购卡片\",\n",
    "        \"点击CTR_点到商品详情页\",\n",
    "        \"点开加购卡片_转化率\",\n",
    "        \"加购成功API_转化率\",\n",
    "        \"总下单数\",\n",
    "        \"总下单用户数\",\n",
    "        \"总下单gmv\",\n",
    "        \"订单均价\",\n",
    "        \"用户平均gmv\",\n",
    "        \"日期范围\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# 显示结果\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result.to_csv(f\"./商场价格展示优化AB实验结果_0910_{ds_yesterday}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_all_df.columns)\n",
    "print(merged_all_df['page_name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 先计算分页面的点击转化p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "user_merged_all_df = pandasql.sqldf(\n",
    "    \"\"\"\n",
    "                                  select cust_id,variant_id,page_name,\n",
    "                                  sum(sku_view_cnt) as SKU浏览总次数,\n",
    "                                  sum(点开商品详情页次数) as 商品详情页点击总次数,\n",
    "                                  sum(点开购物车卡片次数) as 购物车卡片点击总次数,\n",
    "                                  sum(CAST(COALESCE(added_quantity, 0) AS INTEGER)) as SKU加购总件数,\n",
    "                                  sum(CAST(COALESCE(add_cart_cnt, 0) AS INTEGER)) as 加购成功总次数\n",
    "                                  from merged_all_df\n",
    "                                  group by cust_id,variant_id,page_name\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "css = \"\"\"\n",
    "<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css\" integrity=\"sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm\" crossorigin=\"anonymous\">\n",
    "<style type=\\\"text/css\\\">\n",
    "#abTesting table,#abTesting .table {\n",
    "    color: #333;\n",
    "    font-family: unset;\n",
    "    font-size: 12px;\n",
    "    line-height: 1.5;\n",
    "    width: 1024px;\n",
    "    border-collapse:\n",
    "    collapse; \n",
    "    border-spacing: 0;\n",
    "    font-family: \"SF Pro SC\", \"SF Pro Text\", \"SF Pro Icons\", \"PingFang SC\", \"Helvetica Neue\", \"Helvetica\", \"Arial\", sans-serif;\n",
    "}\n",
    "\n",
    "tr{\n",
    "    border-bottom: 1px solid #C1C3D1;\n",
    "}\n",
    "\n",
    "tr:nth-child(even) {\n",
    "    background-color: #F8F8F8;\n",
    "}\n",
    "\n",
    "td, th {\n",
    "    /* border: 1px solid transparent; No more visible border */\n",
    "    height: 30px;\n",
    "}\n",
    "\n",
    "#abTesting table td,#abTesting .table td{\n",
    "    padding: 0.1rem .75rem;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "\n",
    "th {\n",
    "    background-color: #DFDFDF; /* Darken header a bit */\n",
    "    font-weight: bolder;\n",
    "    min-width: 100px;\n",
    "    text-align: center;\n",
    "}\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def display_p_value_below_005(row):\n",
    "    p_value = row[\"p_value\"]\n",
    "    color = \"black\"\n",
    "    if p_value is not None and p_value <= 0.05:\n",
    "        color = \"red\"\n",
    "    return f\"\"\"<span style='font-weight:bolder;color:{color};'>{p_value}</span>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert np.float64 values to regular floats for JSON compatibility\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "def convert_np_float64(obj):\n",
    "    if isinstance(obj, np.float64):\n",
    "        return round(float(obj), 4)\n",
    "    return round(obj, 4)\n",
    "\n",
    "\n",
    "# 计算每组的平均值、中位数和百分位数\n",
    "def get_stats(group: pd.Series):\n",
    "    return {\n",
    "        \"avg\": convert_np_float64(group.mean()),\n",
    "        \"median\": convert_np_float64(group.median()),\n",
    "        \"total_cnt\": convert_np_float64(group.count()),\n",
    "        \"total_sum\": convert_np_float64(group.sum()),\n",
    "        \"75th_percentile\": convert_np_float64(group.quantile(0.75)),\n",
    "        \"90th_percentile\": convert_np_float64(group.quantile(0.90)),\n",
    "        \"95th_percentile\": convert_np_float64(group.quantile(0.95)),\n",
    "    }\n",
    "\n",
    "\n",
    "# 计算两个变体之间指定指标的t检验并返回统计信息的函数\n",
    "def calculate_p_values(df, metric, variant1=\"V1\", variant2=\"V2\"):\n",
    "    group1 = df[df[\"variant_id\"] == variant1][metric]\n",
    "    group2 = df[df[\"variant_id\"] == variant2][metric]\n",
    "\n",
    "    # 执行双样本t检验\n",
    "    t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=False)\n",
    "\n",
    "    # group1_stats = get_stats(group1)\n",
    "    group2_stats = get_stats(group2)\n",
    "    group2_stats[\"p_value\"] = convert_np_float64(p_value)\n",
    "    group2_stats[\"metric\"] = metric\n",
    "    group2_stats[\"variant\"] = variant2\n",
    "\n",
    "    return group2_stats\n",
    "\n",
    "\n",
    "# Function to highlight cells based on p-value\n",
    "def highlight_p_value(val):\n",
    "    if pd.notnull(val) and val < 0.05:\n",
    "        return \"background-color: light-purple\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# Example: Calculate p-values for each metric between V1 and other variants\n",
    "metrics = [\n",
    "    \"SKU浏览总次数\",\n",
    "    \"商品详情页点击总次数\",\n",
    "    \"购物车卡片点击总次数\",\n",
    "    \"SKU加购总件数\",\n",
    "    \"加购成功总次数\",\n",
    "]\n",
    "variants = [\"V2\", \"V3\", \"V4\"]\n",
    "\n",
    "html_content = css\n",
    "\n",
    "for page_name in merged_all_df[\"page_name\"].unique():\n",
    "    print(f\"\\n\\n>>>> 开始计算页面:{page_name} 的p-value:\\n\")\n",
    "    df = user_merged_all_df[user_merged_all_df[\"page_name\"] == page_name]\n",
    "    # Store p-values\n",
    "    p_values = []\n",
    "\n",
    "    for metric in metrics:\n",
    "        group_v1 = df[df[\"variant_id\"] == \"V1\"][metric]\n",
    "        v1_stats = get_stats(group_v1)\n",
    "        v1_stats[\"p_value\"] = None\n",
    "        v1_stats[\"metric\"] = metric\n",
    "        v1_stats[\"variant\"] = \"V1\"\n",
    "        v1_stats[\"page_name\"] = page_name\n",
    "        p_values.append(v1_stats)\n",
    "\n",
    "        for variant in variants:\n",
    "            p_value = calculate_p_values(df, metric, variant1=\"V1\", variant2=variant)\n",
    "            p_value[\"page_name\"] = page_name\n",
    "            p_values.append(p_value)\n",
    "\n",
    "    df_to_display = pd.DataFrame(p_values)\n",
    "    display(df_to_display)\n",
    "\n",
    "    df_to_display[\"P-value\"] = df_to_display.apply(display_p_value_below_005, axis=1)\n",
    "\n",
    "    html_content = html_content + df_to_display[\n",
    "        [\n",
    "            \"median\",\n",
    "            \"75th_percentile\",\n",
    "            \"90th_percentile\",\n",
    "            \"95th_percentile\",\n",
    "            \"avg\",\n",
    "            \"P-value\",\n",
    "            \"metric\",\n",
    "            \"variant\",\n",
    "            \"page_name\",\n",
    "        ]\n",
    "    ].to_html(escape=False, index=False, classes=\"table dataframe\")\n",
    "\n",
    "\n",
    "html_content = f\"\"\"<html><head><meta charset=\"UTF-8\">\n",
    "<meta name=\"title\" content=\"商城价格展示优化AB实验结果_0910-{ds_by_yeaterday}\">\n",
    "</head><body>\n",
    "<h2>当P-value <= 0.05时表示实验结果统计学显著</h2>\n",
    "<span>统计学显著时，既可能表示该试验组是好于对照组，也可能是坏于对照组</span>\n",
    "<div id=\"abTesting\">{html_content}</div></body></html>\"\"\"\n",
    "file_path = f\"./商城价格展示优化AB实验结果_{ds_by_yeaterday}.html\"\n",
    "\n",
    "# 保存HTML到本地文件：\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "print(f\"写入HTML成功！{file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算下单的p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_orders_df.columns)\n",
    "\n",
    "# 确保 '总下单gmv' 和 '订单均价' 列为浮点型\n",
    "user_orders_df['总下单gmv'] = user_orders_df['总下单gmv'].astype(float)\n",
    "user_orders_df['订单均价'] = user_orders_df['订单均价'].astype(float)\n",
    "\n",
    "print(\"'总下单gmv' 列的数据类型:\", user_orders_df['总下单gmv'].dtype)\n",
    "print(\"'订单均价' 列的数据类型:\", user_orders_df['订单均价'].dtype)\n",
    "\n",
    "# Example: Calculate p-values for each metric between V1 and other variants\n",
    "metrics = [\"order_cnt\", \"总下单gmv\", \"订单均价\"]\n",
    "variants = [\"V2\", \"V3\", \"V4\"]\n",
    "\n",
    "order_html_content = css\n",
    "\n",
    "p_values = []\n",
    "\n",
    "for metric in metrics:\n",
    "    group_v1 = user_orders_df[user_orders_df[\"variant_id\"] == \"V1\"][metric]\n",
    "    v1_stats = get_stats(group_v1)\n",
    "    v1_stats[\"p_value\"] = None\n",
    "    v1_stats[\"metric\"] = metric\n",
    "    v1_stats[\"variant\"] = \"V1\"\n",
    "    p_values.append(v1_stats)\n",
    "\n",
    "    for variant in variants:\n",
    "        p_value = calculate_p_values(user_orders_df, metric, variant1=\"V1\", variant2=variant)\n",
    "        p_values.append(p_value)\n",
    "\n",
    "order_p_value_df = pd.DataFrame(p_values)\n",
    "display(order_p_value_df)\n",
    "\n",
    "order_p_value_df[\"P-value\"] = order_p_value_df.apply(display_p_value_below_005, axis=1)\n",
    "\n",
    "order_html_content = order_html_content + order_p_value_df[\n",
    "    [\n",
    "        \"median\",\n",
    "        \"75th_percentile\",\n",
    "        \"90th_percentile\",\n",
    "        \"95th_percentile\",\n",
    "        \"avg\",\n",
    "        \"P-value\",\n",
    "        \"metric\",\n",
    "        \"variant\",\n",
    "    ]\n",
    "].to_html(escape=False, index=False, classes=\"table dataframe\")\n",
    "\n",
    "\n",
    "order_html_content = f\"\"\"<html><head><meta charset=\"UTF-8\">\n",
    "<meta name=\"title\" content=\"商城价格展示优化AB实验结果_下单转化_0910-{ds_by_yeaterday}\">\n",
    "</head><body>\n",
    "<h2>当P-value <= 0.05时表示实验结果统计学显著</h2>\n",
    "<span>统计学显著时，既可能表示该试验组是好于对照组，也可能是坏于对照组</span>\n",
    "<div id=\"abTesting\">{order_html_content}</div></body></html>\"\"\"\n",
    "file_path = f\"./商城价格展示优化AB实验结果_下单转化_{ds_by_yeaterday}.html\"\n",
    "\n",
    "# 保存HTML到本地文件：\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(order_html_content)\n",
    "\n",
    "print(f\"写入HTML成功！{file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
