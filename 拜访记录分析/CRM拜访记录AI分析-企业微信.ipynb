{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# Expand the `~` to the full path and append it to `sys.path`\n",
    "full_path = os.path.expanduser(\"~/Documents/github/aliyun-devops\")\n",
    "sys.path.append(full_path)\n",
    "\n",
    "from odps_client import get_odps_sql_result_as_df\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "ds = (datetime.now() - timedelta(days=1)).strftime(\"%Y%m%d\")\n",
    "\n",
    "# Create a directory for the markdown files if it doesn't exist\n",
    "output_dir = f\"output_wecomm_{ds}\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the base64 encoding library.\n",
    "import base64, os, time\n",
    "import logging\n",
    "\n",
    "# Configure the logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "proxy_object = {\"http\": \"http://127.0.0.1:8001\", \"https\": \"http://127.0.0.1:8001\"}\n",
    "\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client_gpt4o = AzureOpenAI(\n",
    "    api_version=\"2024-03-01-preview\",\n",
    "    azure_endpoint=\"https://xm-ai-us2.openai.azure.com\",\n",
    "    api_key=os.getenv(\"AZURE_GPT4O_API_KEY\", \"\"),\n",
    ")\n",
    "\n",
    "client_gpt4o_mini = AzureOpenAI(\n",
    "    api_version=\"2024-03-01-preview\",\n",
    "    azure_endpoint=\"https://xm-ai-us.openai.azure.com\",\n",
    "    api_key=os.getenv(\"AZURE_GPT4O_MINI_API_KEY\", \"\"),\n",
    ")\n",
    "\n",
    "\n",
    "def call_azure_openai(\n",
    "    messages=[], retrying=1, is_gpt4o=False, json=True, max_tokens=16384\n",
    ") -> (str, bool):\n",
    "    if retrying < 0:\n",
    "        return \"超过了最大重试次数\", False\n",
    "    completion = None\n",
    "    ## gpt3.5:  gpt-35-turbo-16k,\n",
    "    ## got4o:   gpt-4o\n",
    "    ## got4o-mini:   gpt-4o-mini\n",
    "    model = \"gpt-4o-mini\"\n",
    "    client_to_use = client_gpt4o_mini\n",
    "    if is_gpt4o:\n",
    "        logging.info(f\"using GPT-4o...:{messages}\")\n",
    "        model = \"gpt-4o\"\n",
    "        client_to_use = client_gpt4o\n",
    "    try:\n",
    "        completion = client_to_use.chat.completions.create(\n",
    "            model=model,\n",
    "            temperature=0.1,\n",
    "            max_tokens=max_tokens,\n",
    "            messages=messages,\n",
    "            response_format={\"type\": \"json_object\"} if json else {\"type\": \"text\"},\n",
    "        )\n",
    "        response = completion.choices[0].message.content\n",
    "        if (\n",
    "            len(completion.choices) <= 0\n",
    "            or f\"{completion.choices[0].finish_reason}\" == \"content_filter\"\n",
    "        ):\n",
    "            return f\"azure过滤了本次请求:{completion.choices[0].to_dict()}\", False\n",
    "        if response is None:\n",
    "            logging.info(f\"azure API返回了异常:{completion.to_dict()}\")\n",
    "            time.sleep(10)\n",
    "            return call_azure_openai(\n",
    "                messages=messages,\n",
    "                retrying=retrying - 1,\n",
    "                is_gpt4o=is_gpt4o,\n",
    "            )\n",
    "        logging.info(f\"total usage:{completion.usage}\")\n",
    "        return response, True\n",
    "    except Exception as e:\n",
    "        logging.info(\n",
    "            f\"请求azure接口报错了:{e}\\n messages:{messages}, completion:{completion}\"\n",
    "        )\n",
    "        if retrying <= 0 or \"Error code: 400\" in f\"{e}\":\n",
    "            return f\"{e}\", False\n",
    "        logging.info(f\"重试中...{retrying}, messages:{messages}\")\n",
    "        return call_azure_openai(\n",
    "            messages=messages,\n",
    "            retrying=retrying - 1,\n",
    "            is_gpt4o=is_gpt4o,\n",
    "        )\n",
    "\n",
    "\n",
    "def call_ai_api_to_get_extract_visit_info(visit_text=\"\"):\n",
    "    result = {}\n",
    "    json_text, is_ok = call_azure_openai(\n",
    "        is_gpt4o=False,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"\"\"\n",
    "用户会给发给你一系列销售员对客户的拜访记录，请你用JSON回答以下几个问题：\n",
    "- 客户是否有跟销售员互动？\n",
    "- 销售向客户推荐了哪些具体的活动？\n",
    "- 销售向客户推荐了哪些具体的商品？\n",
    "- 客户的主要采买渠道？\n",
    "- 客户对公司的产品有什么看法？(请列明具体的产品名)\n",
    "- 客户对公司的配送服务有什么看法？\n",
    "- 客户对公司的评价是怎样的？（正向/负向/中立/无法判断）\n",
    "- 客户不愿意下单的原因？\n",
    "- 销售员本次拜访的主要目的？\n",
    "- 销售员解决了客户哪些问题？\n",
    "- 拜访记录完整性打分？（0-100分，100分表示非常完整，0分表示非常不完整）\n",
    "\n",
    "**请注意，‘安佳’，‘铁塔’一般来说是商品名字，而不太可能是活动名字，活动名字一般带有‘专享’、‘清仓’、‘特价’、‘活动’等字样**\n",
    "**请你完全基于销售员的拜访记录内容来回答以上问题，如果拜访内容中找不到问题的答案，请回答‘无’**\n",
    "**请你用问题的标题做JSON的key，答案做value，比如：**\n",
    "{\n",
    "  \"客户是否有跟销售员互动\": \"是,交流了2句话\",\n",
    "  \"销售向客户推荐了哪些具体的活动\": \"无\",\n",
    "  \"销售向客户推荐了哪些具体的商品\": \"无\",\n",
    "  \"客户的主要采买渠道\": \"无\",\n",
    "  \"客户对公司的产品有什么看法\": \"无\",\n",
    "  \"客户对公司的配送服务有什么看法 \"无\",\n",
    "  \"客户对公司的评价是怎样的\": \"无法判断\",\n",
    "  \"客户不愿意下单的原因\": \"无\",\n",
    "  \"销售员本次拜访的主要目的\": \"通知客户服务升级\",\n",
    "  \"销售员解决了客户哪些问题\": \"无\",\n",
    "  \"拜访记录完整性打分\": 10,\n",
    "}\n",
    "\"\"\",\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": visit_text}],\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    logging.info(f\"json_text:{json_text}, visit_text:{visit_text}\")\n",
    "    return json_text\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "date_of_now = datetime.now().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 先获取聊天记录\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sql=f\"\"\"\n",
    "SELECT  ds\n",
    "        ,form AS msg_from\n",
    "        ,tolist\n",
    "        ,body\n",
    "        ,msgtime\n",
    "FROM    summerfarm_tech.dwd_log_wecom_di\n",
    "WHERE   ds = '{ds}'\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "wecom_log_df = get_odps_sql_result_as_df(sql=sql)\n",
    "wecom_log_df['tolist'] = wecom_log_df['tolist'].apply(lambda x: json.loads(x if x is not None else '[\"\"]')[0])\n",
    "# Display the top 20 rows of the wecom_log_df dataframe\n",
    "wecom_log_df['conversation_group'] = wecom_log_df.apply(lambda row: '-'.join(sorted([f\"{row['msg_from']}\", f\"{row['tolist']}\"])), axis=1)\n",
    "# wecom_log_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------绑定企微的客户名单\n",
    "sql_wecom=f\"\"\"\n",
    "SELECT  oc.m_id\n",
    "        ,c.cust_name\n",
    "        ,array_join(collect_set(wx.user_id),',') 绑定微信ID\n",
    "        ,wx.external_userid\n",
    "        ,MAX(create_time) 绑定微信时间\n",
    "FROM    summerfarm_tech.ods_merchant_sub_account_df oc\n",
    "LEFT JOIN summerfarm_tech.dim_cust_df c\n",
    "ON      oc.m_id = c.cust_id\n",
    "AND     c.ds = MAX_PT('summerfarm_tech.dim_cust_df')\n",
    "AND     c.ds BETWEEN c.start_at AND c.end_at\n",
    "LEFT JOIN summerfarm_tech.ods_wechat_user_info_df wx\n",
    "ON      oc.unionid = wx.unionid\n",
    "AND     wx.ds = MAX_PT('summerfarm_tech.ods_wechat_user_info_df')\n",
    "AND     wx.status = 1\n",
    "WHERE   oc.unionid IS NOT NULL\n",
    "AND     oc.ds = MAX_PT('summerfarm_tech.ods_merchant_sub_account_df')\n",
    "AND     oc.type = 0\n",
    "AND     wx.user_id IS NOT NULL\n",
    "GROUP BY oc.m_id\n",
    "         ,c.cust_name\n",
    "         ,wx.external_userid\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "wecom_user_df = get_odps_sql_result_as_df(sql=sql_wecom)\n",
    "# wecom_user_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "external_userid_to_mid_map = {}\n",
    "\n",
    "for index, row in wecom_user_df.iterrows():\n",
    "    external_userid_to_mid_map[row[\"external_userid\"]] = (\n",
    "        f\"{row['cust_name']}:{row['m_id']}\"\n",
    "    )\n",
    "\n",
    "conversation_groups = wecom_log_df[\"conversation_group\"].unique()\n",
    "\n",
    "all_conversation_list = []\n",
    "\n",
    "for conversation_group in conversation_groups:\n",
    "    # print(f\"conversation_group:{conversation_group}\")\n",
    "    bd_wecom_id = None\n",
    "    from_to_pair = conversation_group.split(\"-\")\n",
    "    if \"wmndqQCQAA\" not in from_to_pair[0]:\n",
    "        bd_wecom_id = from_to_pair[0]\n",
    "    elif len(from_to_pair) > 1 and \"wmndqQCQAA\" not in from_to_pair[1]:\n",
    "        bd_wecom_id = from_to_pair[1]\n",
    "    else:\n",
    "        print(f\"找不到BD ID:{conversation_group}\")\n",
    "    mid = None\n",
    "    mname = None\n",
    "    conversation_start_time = None\n",
    "    conversation_end_time = None\n",
    "    conversation_group_df = wecom_log_df[\n",
    "        wecom_log_df[\"conversation_group\"] == conversation_group\n",
    "    ]\n",
    "\n",
    "    conversation_group_df[\"msgtime\"] = pd.to_datetime(conversation_group_df[\"msgtime\"])\n",
    "    conversation_group_df.sort_values(by=\"msgtime\", ascending=True, inplace=True)\n",
    "    conversation = {\"conversation_group\": conversation_group}\n",
    "    conversation_list = []\n",
    "    for index, row in conversation_group_df.iterrows():\n",
    "        if conversation_start_time is None:\n",
    "            conversation_start_time = row[\"msgtime\"]\n",
    "        conversation_end_time = row[\"msgtime\"]\n",
    "        msg_from = external_userid_to_mid_map.get(row[\"msg_from\"], row[\"msg_from\"])\n",
    "        msg_to = external_userid_to_mid_map.get(row[\"tolist\"], row[\"tolist\"])\n",
    "        if mid is None:\n",
    "            if row[\"tolist\"] is not None and \"wmndqQCQAA\" in row[\"tolist\"]:\n",
    "                mid = f\"{msg_to}:{msg_to}\".split(\":\")[1]\n",
    "                mname = msg_to.split(\":\")[0]\n",
    "            elif row[\"msg_from\"] is not None and \"wmndqQCQAA\" in row[\"msg_from\"]:\n",
    "                mid = f\"{msg_from}:{msg_from}\".split(\":\")[1]\n",
    "                mname = msg_from.split(\":\")[0]\n",
    "        conversation_list.append(\n",
    "            f\"[{row['msgtime']}] {msg_from} -> {msg_to}: {json.loads(row['body'] or '{}').get('content','非文本')}\"\n",
    "        )\n",
    "    conversation[\"conversation_list\"] = conversation_list\n",
    "    conversation[\"商户ID\"] = mid\n",
    "    conversation[\"商户名\"] = mname\n",
    "    conversation[\"会话开始时间\"] = conversation_start_time\n",
    "    conversation[\"会话结束时间\"] = conversation_end_time\n",
    "    conversation[\"BD企业微信ID\"] = bd_wecom_id\n",
    "    all_conversation_list.append(conversation)\n",
    "\n",
    "all_conversation_df = pd.DataFrame(all_conversation_list)\n",
    "all_conversation_df.to_csv(f\"{output_dir}/all_conversation_df.csv\", index=False)\n",
    "# all_conversation_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staffname_list = [\"白津源\", \"宋懿航\", \"李梦婷\", \"陈汉文\"]\n",
    "staffname_list = [f\"'{staffname}'\" for staffname in staffname_list]\n",
    "staffname_list = \",\".join(staffname_list)\n",
    "\n",
    "mid_to_bd_sql = f\"\"\"\n",
    "SELECT  b.cust_id\n",
    "        ,b.cust_name 商户名\n",
    "        ,c.bd_name\n",
    "        ,c.bd_id\n",
    "        ,b.abandon_date\n",
    "        ,CASE   WHEN d.last_order_time IS NULL THEN '从未下单'\n",
    "                ELSE '已下单'\n",
    "        END AS 是否下过单\n",
    "        ,DATEDIFF(GETDATE(),d.last_order_time,'dd') AS 距离上次下单天数\n",
    "        ,od.历史下单数\n",
    "        ,od.历史总下单金额\n",
    "        ,DATEDIFF(GETDATE(),d.register_time,'dd') AS 注册天数\n",
    "        ,c.m1_name AS M1负责人\n",
    "        ,c.m2_name AS M2负责人\n",
    "        ,c.m3_name AS M3负责人\n",
    "        ,c.zone_name AS 销售区域\n",
    "FROM    summerfarm_tech.dim_cust_df b\n",
    "LEFT JOIN summerfarm_tech.dim_bd_df c\n",
    "ON      c.bd_id = b.bd_id\n",
    "AND     c.ds = MAX_PT('summerfarm_tech.dim_bd_df')\n",
    "LEFT JOIN summerfarm_tech.ods_merchant_df d\n",
    "ON      d.m_id = b.cust_id\n",
    "AND     d.ds = MAX_PT('summerfarm_tech.ods_merchant_df')\n",
    "LEFT JOIN   (\n",
    "                SELECT  m_id\n",
    "                        ,SUM(total_price) 历史总下单金额\n",
    "                        ,COUNT(DISTINCT CASE    WHEN od.status IN (2,3,6) THEN od.order_no END) AS 历史下单数\n",
    "                FROM    summerfarm_tech.ods_orders_df od\n",
    "                WHERE   ds = MAX_PT('summerfarm_tech.ods_orders_df')\n",
    "                GROUP BY m_id\n",
    "            ) od\n",
    "ON      od.m_id = b.cust_id\n",
    "WHERE   b.ds = MAX_PT('summerfarm_tech.dim_cust_df')\n",
    "AND     c.m1_name IS NOT NULL\n",
    "AND     b.abandon_date = 99991231\n",
    "AND     c.is_disabled = 0\n",
    ";\n",
    "\"\"\"\n",
    "print(f\"sql:{mid_to_bd_sql}\")\n",
    "mid_to_bd_df = get_odps_sql_result_as_df(sql=mid_to_bd_sql)\n",
    "mid_to_bd_df.drop_duplicates(\n",
    "    subset=[\"cust_id\"], inplace=True\n",
    ")\n",
    "\n",
    "# mid_to_bd_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming all_conversation_df is already defined in the notebook\n",
    "all_conversation_df['商户ID'] = all_conversation_df['商户ID'].astype(str)\n",
    "mid_to_bd_df['cust_id'] = mid_to_bd_df['cust_id'].astype(str)\n",
    "\n",
    "# Merge the dataframes and append '_y' to duplicate columns from the right dataframe\n",
    "merged_df = all_conversation_df.merge(mid_to_bd_df, how='left', left_on='商户ID', right_on='cust_id', suffixes=('', '_y'))\n",
    "merged_df = merged_df.dropna(subset=['cust_id'])\n",
    "# merged_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"你是一个资深销售主管，擅长分析销售员的客户拜访记录\",\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "def call_ai_api_to_get_insigns(city, csv_string=\"\"):\n",
    "    merged_markdown_result = \"\"\n",
    "    text, is_ok = call_azure_openai(\n",
    "        is_gpt4o=False,\n",
    "        json=False,\n",
    "        messages=[\n",
    "            system_prompt,\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": f\"\"\"以下是你管理的团队销售员的客户拜访记录，作为销售主管，从中你发现了哪些值得注意的现象？\n",
    "    将你发现的每一种现象按照重要程度倒序排列。请你列举数据以阐述其值得你关注的原因。\n",
    "    **请你完全基于CSV的数据做分析，如果用户没有具体的反馈内容，请不要推测。这对公司来说非常重要，我们需要使用真实的客户反馈去调整经营策略**\n",
    "    以下是CSV内容：\\n\\n{csv_string}\"\"\",\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    if not is_ok:\n",
    "        logging.info(f\"call_ai_api_to_get_insigns failed: {text}\")\n",
    "        return \"\"\n",
    "\n",
    "    merged_markdown_result = f\"## {city}团队销售拜访记录AI分析\\n\\n{text}\\n\\n\"\n",
    "\n",
    "    text, is_ok = call_azure_openai(\n",
    "        is_gpt4o=False,\n",
    "        json=False,\n",
    "        messages=[\n",
    "            system_prompt,\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": f\"\"\"作为销售主管，请你分析在这些拜访记录中，有哪些具体的客户提到竞争对手的品比我们的价格低的？\n",
    "                    请你列举出具体的客户名和商品名，以及竞争对手的名称和价格（如果有的话）。\n",
    "                    **请你完全基于CSV的数据做分析，如果用户没有具体的反馈内容，请不要推测。这对公司来说非常重要，我们需要使用真实的客户反馈去调整经营策略**\n",
    "                    以下是拜访记录CSV内容：\\n\\n{csv_string}\"\"\",\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    merged_markdown_result = (\n",
    "        f\"{merged_markdown_result}## 竞争对手情况分析\\n\\n{text}\\n\\n\"\n",
    "    )\n",
    "\n",
    "    text, is_ok = call_azure_openai(\n",
    "        is_gpt4o=False,\n",
    "        json=False,\n",
    "        messages=[\n",
    "            system_prompt,\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": f\"\"\"作为销售主管，请你分析客户长时间未下单的原因中，有哪些值得注意的现象？请你列举每种原因的占比，凸显出每个原因的重要程度。\n",
    "                    **请你完全基于CSV的数据做分析，如果用户没有反馈具体的原因，请不要推测。这对公司来说非常重要，我们需要使用真实的客户反馈去调整经营策略**\n",
    "                    以下是拜访记录CSV内容：\\n\\n{csv_string}\"\"\",\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    merged_markdown_result = (\n",
    "        f\"{merged_markdown_result}## 长时间不下单原因分析\\n\\n{text}\\n\\n\"\n",
    "    )\n",
    "\n",
    "    filename = f\"{city}_销售团队拜访记录分析结果_{ds}.md\"\n",
    "\n",
    "    # Full path for the output file\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "    # Write the merged_markdown_result to the file\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(merged_markdown_result)\n",
    "\n",
    "    print(f\"Markdown file saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "bd_follow_up_record_df=merged_df\n",
    "\n",
    "# bd_follow_up_record_df['communication_time_in_seconds']=bd_follow_up_record_df['communication_time_in_seconds'].astype(int)\n",
    "# bd_follow_up_record_df.drop_duplicates(subset=[\"sessionid\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "bd_follow_up_record_df = bd_follow_up_record_df.dropna(subset=[\"cust_id\"])\n",
    "bd_follow_up_record_df.to_csv(f\"{output_dir}/bd_follow_up_record_df.csv\", index=False)\n",
    "\n",
    "bd_follow_up_record_df.rename(\n",
    "    columns={\n",
    "        \"conversation_list\": \"拜访内容_segments\",\n",
    "        \"bd_name\": \"客户所属BD\",\n",
    "    },\n",
    "    inplace=True,\n",
    "    errors=\"ignore\",\n",
    ")\n",
    "\n",
    "bd_follow_up_record_df['拜访人']=bd_follow_up_record_df['BD企业微信ID']\n",
    "\n",
    "\n",
    "whisper_segments_csv = bd_follow_up_record_df[\n",
    "    [\"商户名\", \"拜访人\", \"是否下过单\", \"距离上次下单天数\", \"拜访内容_segments\"]\n",
    "]\n",
    "whisper_segments_csv[\"拜访内容_segments\"] = whisper_segments_csv[\n",
    "    \"拜访内容_segments\"\n",
    "].apply(lambda segments: \", \".join(segments) if isinstance(segments, list) else \"\")\n",
    "whisper_segments_csv.to_csv(\n",
    "    f\"{output_dir}/拜访内容_企业微信.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign default value for filtered rows\n",
    "filter_condition = bd_follow_up_record_df[\"拜访内容_segments\"].apply(\n",
    "    lambda segments: all(\n",
    "        \"非文本\" in segment or \"您好，您的服务已升级\" for segment in segments\n",
    "    )\n",
    ")\n",
    "\n",
    "default_json_value = json.dumps(\n",
    "    {\n",
    "        \"客户是否有跟销售员互动\": \"无,默认值\",\n",
    "        \"销售向客户推荐了哪些具体的活动\": \"无\",\n",
    "        \"销售向客户推荐了哪些具体的商品\": \"无\",\n",
    "        \"客户的主要采买渠道\": \"无\",\n",
    "        \"客户对公司的产品有什么看法\": \"无\",\n",
    "        \"客户对公司的配送服务有什么看法\": \"无\",\n",
    "        \"客户对公司的评价是怎样的\": \"无\",\n",
    "        \"客户不愿意下单的原因\": \"无\",\n",
    "        \"销售员本次拜访的主要目的\": \"无\",\n",
    "        \"销售员解决了客户哪些问题\": \"无\",\n",
    "        \"拜访记录完整性打分\": 0,\n",
    "    },\n",
    "    ensure_ascii=False,\n",
    ")\n",
    "\n",
    "\n",
    "def create_ai_analytics_for_row(row):\n",
    "    visit_text = f\"对话条数{len(row['拜访内容_segments'])}条, 通话记录:{row['拜访内容_segments']}\"\n",
    "    print(f\"{row['拜访人']}, visit_text:{visit_text}\")\n",
    "    segments = row[\"拜访内容_segments\"]\n",
    "    segments_with_text = [\n",
    "        segment\n",
    "        for segment in segments\n",
    "        if \"非文本\" not in segment and \"您好，您的服务已升级\" not in segment\n",
    "    ]\n",
    "    if len(segments_with_text) == 0:\n",
    "        print(f\"{row['拜访人']}, 没有文本内容, 使用默认值\")\n",
    "        return default_json_value\n",
    "    return call_ai_api_to_get_extract_visit_info(\n",
    "        f\"对话条数{len(segments)}条, 通话记录:{segments_with_text}\"\n",
    "    )\n",
    "\n",
    "\n",
    "bd_follow_up_record_df[\"AI分析\"] = bd_follow_up_record_df.apply(\n",
    "    create_ai_analytics_for_row, axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_follow_up_record_df['拜访记录完整性打分'] = bd_follow_up_record_df['AI分析'].apply(\n",
    "    lambda x: json.loads(x).get('拜访记录完整性打分', '0')\n",
    ")\n",
    "bd_follow_up_record_df['拜访记录完整性打分'] = pd.to_numeric(bd_follow_up_record_df['拜访记录完整性打分'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为哪些打分大于等于60分的聊天记录单独进行'AI总结'\n",
    "\n",
    "\n",
    "def create_ai_summary_for_row(row):\n",
    "    if row[\"拜访记录完整性打分\"] >= 60:\n",
    "        return call_azure_openai(\n",
    "            is_gpt4o=False,\n",
    "            json=False,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": f\"\"\"任务:分析销售员与客户之间的企业微信对话,识别值得公司管理者关注的问题。\n",
    "\n",
    "输出要求:\n",
    "1. 列出明确的、值得管理层注意的内容要点\n",
    "2. 为每个要点标注对应的聊天记录原文出处\n",
    "3. 不要提供建议或解决方案,仅列出需要关注的问题\n",
    "\n",
    "分析框架:\n",
    "- 结合客户的基本情况(如购买历史)\n",
    "- 仔细审视销售员与客户的互动方式\n",
    "- 关注可能影响业务的关键信息或模式，比如竞争对手以及具体商品的价格、客户对我们的配送服务的反馈等等\n",
    "\n",
    "客户类型判断标准:\n",
    "- 距离上次下单天数为空 → 新客户\n",
    "- 距离上次下单天数≤7天 → 活跃客户\n",
    "- 距离上次下单天数>60天 → 流失客户\n",
    "\n",
    "注意事项:\n",
    "- 保持客观,仅基于给定信息进行分析\n",
    "- 确保每个关注点都有明确的聊天记录支持\n",
    "- 如遇模糊情况,可提出作为潜在关注点,但标明不确定性\n",
    "客户距离上次下单天数:{row['距离上次下单天数']}, 客户历史总下单金额:¥{row['历史总下单金额']}, 对话条数:{len(row['拜访内容_segments'])}条\\n\\n\\n拜访内容:\\n{row['拜访内容_segments']}\"\"\",\n",
    "                        }\n",
    "                    ],\n",
    "                },\n",
    "            ],\n",
    "        )[0]\n",
    "\n",
    "    else:\n",
    "        return f\"拜访记录不够完整，无需AI总结, 打分:{row['拜访记录完整性打分']}, 内容:{row['拜访内容_segments']}\"\n",
    "\n",
    "\n",
    "bd_follow_up_record_df[\"AI总结\"] = bd_follow_up_record_df.apply(\n",
    "    create_ai_summary_for_row, axis=1\n",
    ")\n",
    "\n",
    "bd_follow_up_record_df.sort_values(\n",
    "    by=\"拜访记录完整性打分\", ascending=False, inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "keys = []\n",
    "\n",
    "\n",
    "def extract_ai_result(ai_result, key):\n",
    "    return json.loads(ai_result).get(key, \"未知\")\n",
    "\n",
    "\n",
    "for sale_man_name in bd_follow_up_record_df[\"BD企业微信ID\"].unique():\n",
    "    logging.info(f\"开始处理:{sale_man_name}的拜访记录\")\n",
    "    sale_man_df = bd_follow_up_record_df[\n",
    "        bd_follow_up_record_df[\"BD企业微信ID\"] == sale_man_name\n",
    "    ].copy()\n",
    "\n",
    "    # Create a valid filename by replacing any characters that might be problematic in filenames\n",
    "    safe_city_name = \"\".join(\n",
    "        c if c.isalnum() or c in (\"-\", \"_\") else \"_\" for c in sale_man_name\n",
    "    )\n",
    "\n",
    "    # Save the city's records to a CSV file\n",
    "    filename = f\"./{output_dir}/{safe_city_name}_{ds}_拜访记录.csv\"\n",
    "    sale_man_df[\n",
    "        [\n",
    "            \"拜访人\",\n",
    "            \"m1负责人\",\n",
    "            \"商户名\",\n",
    "            \"距离上次下单天数\",\n",
    "            \"拜访记录完整性打分\",\n",
    "            \"历史下单数\",\n",
    "            \"历史总下单金额\",\n",
    "            \"拜访内容_segments\",\n",
    "            \"AI分析\",\n",
    "        ]\n",
    "    ].to_csv(filename, index=False)\n",
    "\n",
    "    print(f\"Saved {len(sale_man_df)} records for {sale_man_name} to {filename}\")\n",
    "\n",
    "    for index, row in sale_man_df.iterrows():\n",
    "        ai_result = json.loads(row[\"AI分析\"])\n",
    "        if not keys:\n",
    "            keys = list(ai_result.keys())\n",
    "            logging.info(f\"keys: {keys}\")\n",
    "            break\n",
    "\n",
    "    for key in keys:\n",
    "        sale_man_df[key] = sale_man_df[\"AI分析\"].apply(\n",
    "            lambda x: extract_ai_result(x, key)\n",
    "        )\n",
    "\n",
    "    display_keys = [\n",
    "        \"销售区域\",\n",
    "        \"拜访人\",\n",
    "        \"m1负责人\",\n",
    "        \"商户名\",\n",
    "        \"距离上次下单天数\",\n",
    "        \"拜访记录完整性打分\",\n",
    "        \"历史下单数\",\n",
    "        \"历史总下单金额\",\n",
    "        \"AI分析\",\n",
    "        \"AI总结\",\n",
    "    ]\n",
    "    display_keys.extend(keys)\n",
    "    sale_man_df[display_keys].to_csv(\n",
    "        f\"./{output_dir}/{safe_city_name}_{ds}_拜访记录_AI分析_展开.csv\", index=False\n",
    "    )\n",
    "\n",
    "    ai_csv_analytics_keys = [\n",
    "        \"销售区域\",\n",
    "        \"拜访人\",\n",
    "        \"m1负责人\",\n",
    "        \"商户名\",\n",
    "        \"距离上次下单天数\",\n",
    "        \"拜访记录完整性打分\",\n",
    "        \"历史下单数\",\n",
    "        \"历史总下单金额\",\n",
    "    ]\n",
    "    ai_csv_analytics_keys.extend(keys)\n",
    "    csv_string = sale_man_df[ai_csv_analytics_keys].to_csv(index=False)\n",
    "\n",
    "    print(f\"{sale_man_name}, \\ncsv_string:{csv_string}\")\n",
    "\n",
    "    call_ai_api_to_get_insigns(csv_string=csv_string, city=safe_city_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = bd_follow_up_record_df[bd_follow_up_record_df['拜访记录完整性打分'] >= 60][['拜访人', '商户名', '商户ID', 'AI总结', '是否下过单', '距离上次下单天数', '历史总下单金额', '历史下单数']]\n",
    "filtered_df['历史下单数'].fillna(0, inplace=True)\n",
    "filtered_df['历史下单数'].astype(int)\n",
    "markdown_content = \"\"\n",
    "\n",
    "for index,row in filtered_df.iterrows():\n",
    "    markdown_content=f\"\"\"{markdown_content}# 客户[{row['商户名']}:{row['商户ID']}]\n",
    "- 销售BD: {row['拜访人']}\n",
    "- 是否下过单: {row['是否下过单']}\n",
    "- 距离上次下单天数: {row['距离上次下单天数']}\n",
    "- 历史总下单情况: {row['历史下单数']}单、{row['历史总下单金额']}元\n",
    "\n",
    "## AI总结:\n",
    "{row['AI总结']}\n",
    "\\n\\n\n",
    "\"\"\"\n",
    "\n",
    "# Define the output file path\n",
    "output_file_path = f\"{output_dir}/filtered_follow_up_records_{ds}.md\"\n",
    "\n",
    "# Write the markdown content to the file\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(markdown_content)\n",
    "\n",
    "print(f\"Markdown file saved: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
