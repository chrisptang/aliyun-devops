{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文件头，准备各类API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List\n",
    "import shutil\n",
    "\n",
    "from alibabacloud_sls20201230.client import Client as Sls20201230Client\n",
    "from alibabacloud_tea_openapi import models as open_api_models\n",
    "from alibabacloud_sls20201230 import models as sls_20201230_models\n",
    "from alibabacloud_tea_util import models as util_models\n",
    "from alibabacloud_tea_util.client import Client as UtilClient\n",
    "import os\n",
    "import pandas as pd\n",
    "from odps import ODPS, DataFrame\n",
    "from datetime import datetime, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import concurrent.futures\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "# Configure the logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "ALIBABA_CLOUD_ACCESS_KEY_ID = os.getenv(\"ALIBABA_CLOUD_ACCESS_KEY_ID\")\n",
    "ALIBABA_CLOUD_ACCESS_KEY_SECRET = os.getenv(\"ALIBABA_CLOUD_ACCESS_KEY_SECRET\")\n",
    "FEISHU_XGPT_APP_SECRET = os.getenv(\"FEISHU_XGPT_APP_SECRET\")\n",
    "AZURE_GPT4O_API_KEY = os.getenv(\"AZURE_GPT4O_API_KEY\")\n",
    "AZURE_API_KEY = os.getenv(\"AZURE_API_KEY\")\n",
    "CALL_AI_SERVICE = os.getenv(\"CALL_AI_SERVICE\", \"true\")\n",
    "\n",
    "ds_to_run = datetime.now().strftime(\"%Y-%m-%d 00:00:00\")\n",
    "ds_to_run = datetime.strptime(ds_to_run, \"%Y-%m-%d 00:00:00\") - timedelta(days=1)\n",
    "ds_to_run = ds_to_run.strftime(\"%Y%m%d\")\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--ds_to_run\",\n",
    "    default=ds_to_run,\n",
    "    help=\"指定跑哪一天的数据，格式: 20250520\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--ACCESS_KEY_ID\",\n",
    "    default=ALIBABA_CLOUD_ACCESS_KEY_ID,\n",
    "    help=\"ALIBABA_CLOUD_ACCESS_KEY_ID\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--ACCESS_KEY_SECRET\",\n",
    "    default=ALIBABA_CLOUD_ACCESS_KEY_SECRET,\n",
    "    help=\"ALIBABA_CLOUD_ACCESS_KEY_SECRET\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--FEISHU_XGPT_APP_SECRET\",\n",
    "    default=FEISHU_XGPT_APP_SECRET,\n",
    "    help=\"飞书的FEISHU_XGPT_APP_SECRET\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--AZURE_API_KEY\",\n",
    "    default=AZURE_API_KEY,\n",
    "    help=\"AZURE_API_KEY\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--AZURE_GPT4O_API_KEY\", default=AZURE_GPT4O_API_KEY, help=\"AZURE_GPT4O_API_KEY\"\n",
    ")\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "logging.info(f\"Parsed args: {args}\")\n",
    "logging.info(f\"Unknown args: {unknown}\")\n",
    "logging.info(args)\n",
    "ds_to_run = args.ds_to_run\n",
    "\n",
    "DATA_PATH = f\"./data/{ds_to_run}\"\n",
    "\n",
    "logging.info(f\"ds_to_run:{ds_to_run}\")\n",
    "\n",
    "default_segment_duration = int(os.getenv(\"SEGMENT_DURATION\", \"45\"))\n",
    "\n",
    "odps = ODPS(\n",
    "    args.ACCESS_KEY_ID,\n",
    "    args.ACCESS_KEY_SECRET,\n",
    "    project=\"summerfarm_ds_dev\",\n",
    "    endpoint=\"http://service.cn-hangzhou.maxcompute.aliyun.com/api\",\n",
    ")\n",
    "\n",
    "config = open_api_models.Config(\n",
    "    access_key_id=args.ACCESS_KEY_ID,\n",
    "    access_key_secret=args.ACCESS_KEY_SECRET,\n",
    ")\n",
    "# Endpoint 请参考 https://api.aliyun.com/product/Sls\n",
    "config.endpoint = f\"cn-hangzhou.log.aliyuncs.com\"\n",
    "sls_client = Sls20201230Client(config)\n",
    "\n",
    "\n",
    "def create_dir_if_not_exist(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "\n",
    "\n",
    "create_dir_if_not_exist(DATA_PATH)\n",
    "\n",
    "\n",
    "def get_odps_sql_result_as_df(sql):\n",
    "    logging.info(f\"ODPS SQL:\\n{sql}\")\n",
    "    instance = odps.execute_sql(\n",
    "        sql,\n",
    "        hints={\"odps.sql.hive.compatible\": True, \"odps.sql.type.system.odps2\": True},\n",
    "    )\n",
    "    instance.wait_for_success()\n",
    "    pd_df = None\n",
    "    with instance.open_reader(tunnel=True) as reader:\n",
    "        # type of pd_df is pandas DataFrame\n",
    "        pd_df = reader.to_pandas()\n",
    "\n",
    "    if pd_df is not None:\n",
    "        logging.info(f\"columns:{pd_df.columns}\")\n",
    "        return pd_df\n",
    "    return None\n",
    "\n",
    "\n",
    "def add_new_column_to_table(table_name, column_name):\n",
    "    if \"summerfarm_ds.\" not in table_name:\n",
    "        table_name = f\"summerfarm_ds.{table_name}\"\n",
    "    sql = f\"ALTER TABLE {table_name} ADD COLUMNS ({column_name} STRING);\"\n",
    "    instance = odps.execute_sql(sql)\n",
    "    instance.wait_for_success()\n",
    "    logging.info(f\"添加新字段成功:{table_name}, {column_name}\")\n",
    "\n",
    "\n",
    "def ensure_all_df_columns_in_odps_table(df, table_name):\n",
    "    if \"summerfarm_ds.\" not in table_name:\n",
    "        table_name = f\"summerfarm_ds.{table_name}\"\n",
    "    if not odps.exist_table(table_name):\n",
    "        logging.info(f\"表不存在:{table_name}\")\n",
    "        return True\n",
    "    table = odps.get_table(table_name)\n",
    "    column_names = set([column.name for column in table.table_schema])\n",
    "    column_names_out = \",\\n\".join(column_names)\n",
    "    logging.info(f\"DaraFrame字段合集:\\n\\n{column_names_out}\")\n",
    "    df_columns = df.columns.tolist()\n",
    "    for df_col in df_columns:\n",
    "        df_col = df_col.lower()\n",
    "        if df_col not in column_names:\n",
    "            logging.info(f\"新字段:{df_col}, ODPS全部的字段:{column_names}\")\n",
    "            add_new_column_to_table(table_name, df_col)\n",
    "    return True\n",
    "\n",
    "\n",
    "def write_pandas_df_into_odps_overwrite(df, table_name, partition_spec):\n",
    "    if df is None or len(df) <= 0:\n",
    "        logging.info(f\"数据DF为空, table:{table_name}\")\n",
    "        return False\n",
    "    ensure_all_df_columns_in_odps_table(df, table_name)\n",
    "    exception = None\n",
    "    try:\n",
    "        odps_df = DataFrame(df)\n",
    "        odps_df.persist(\n",
    "            table_name,\n",
    "            partition=partition_spec,\n",
    "            drop_partition=False,\n",
    "            create_partition=True,\n",
    "            overwrite=True,\n",
    "            lifecycle=365,\n",
    "        )\n",
    "        logging.info(f\"成功写入odps:{table_name}, partition_spec:{partition_spec}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        exception = e\n",
    "        logging.info(f\"写入ODPS不成功:{table_name}\", e)\n",
    "        raise exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 飞书接口认证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import wave\n",
    "import requests\n",
    "import ffmpeg\n",
    "import re\n",
    "\n",
    "def get_feishu_token():\n",
    "    url = \"https://open.feishu.cn/open-apis/auth/v3/app_access_token/internal\"\n",
    "    token = requests.post(\n",
    "        url=url,\n",
    "        json={\"app_id\": \"cli_a450bff26fbbd00d\", \"app_secret\": args.FEISHU_XGPT_APP_SECRET},\n",
    "    ).json()\n",
    "    logging.info(token)\n",
    "    return token\n",
    "\n",
    "\n",
    "feishu_token = get_feishu_token()\n",
    "feishu_headers_with_token = {\n",
    "    \"Authorization\": f'Bearer {feishu_token[\"tenant_access_token\"]}',\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "logging.info(feishu_headers_with_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wav文件下载和识别接口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "import os\n",
    "import base64\n",
    "import requests\n",
    "import logging\n",
    "import time\n",
    "import string\n",
    "import random\n",
    "\n",
    "text_map = {}\n",
    "failed_wav_files={}\n",
    "\n",
    "def generate_random_string(length=16):\n",
    "    letters_and_digits = string.ascii_letters + string.digits\n",
    "    return ''.join(random.choice(letters_and_digits) for _ in range(length))\n",
    "\n",
    "random_string = generate_random_string()\n",
    "print(random_string)\n",
    "\n",
    "def dump_failed_json_to_file(json_object, file_id):\n",
    "    with open(f\"{DATA_PATH}/failed_{file_id}.json\", \"w\") as f:\n",
    "        json.dump(json_object, f, indent=4)\n",
    "\n",
    "\n",
    "def get_file_id_from_base64_content(s, num=16):\n",
    "    # return \"\".join(re.findall(r\"[a-zA-Z0-9]\", s))[:num]\n",
    "    return generate_random_string(num)\n",
    "\n",
    "\n",
    "def get_dir_from_path(file_path):\n",
    "    return os.path.dirname(file_path)\n",
    "\n",
    "\n",
    "def split_wav_file(input_file, segment_duration=default_segment_duration):\n",
    "    output_files = []\n",
    "    basename, _ = os.path.splitext(os.path.basename(input_file))\n",
    "\n",
    "    try:\n",
    "        output_dir = get_dir_from_path(input_file)\n",
    "        # Open the input file\n",
    "        stream = ffmpeg.input(input_file)\n",
    "\n",
    "        # Set the output format and codec\n",
    "        stream = ffmpeg.output(\n",
    "            stream,\n",
    "            os.path.join(output_dir, f\"{basename}_segment_%03d.wav\"),\n",
    "            codec=\"copy\",\n",
    "            f=\"segment\",\n",
    "            segment_time=segment_duration,\n",
    "        )\n",
    "\n",
    "        # Run the FFmpeg command\n",
    "        ffmpeg.run(stream, overwrite_output=True, quiet=True)\n",
    "\n",
    "        # Get the list of output files\n",
    "        output_files = [\n",
    "            os.path.join(output_dir, f)\n",
    "            for f in os.listdir(output_dir)\n",
    "            if f.startswith(f\"{basename}_segment_\") and f.endswith(\".wav\")\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"切分wav文件:{input_file}出错了:{e}\", e)\n",
    "\n",
    "    output_files.sort()\n",
    "    return output_files\n",
    "\n",
    "\n",
    "def get_base64encoded_content_of_wav(wav_file):\n",
    "    logging.info(f\"wav_file:{wav_file}\")\n",
    "\n",
    "    output = \"\"\n",
    "\n",
    "    # Create the input stream\n",
    "    input_stream = ffmpeg.input(wav_file)\n",
    "\n",
    "    # Configure the output stream\n",
    "    output_stream = input_stream.output(\n",
    "        \"pipe:\", acodec=\"pcm_s16le\", format=\"s16le\", ac=1, ar=16000\n",
    "    )\n",
    "\n",
    "    # Run the FFmpeg command and capture the output\n",
    "    output, _ = ffmpeg.run(output_stream, capture_stdout=True, quiet=True)\n",
    "\n",
    "    # The output is a bytes object containing the raw PCM data\n",
    "    pcm_data = output\n",
    "    return base64.b64encode(pcm_data).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def recognize_feishu_api_base64_content(base64_pcm_data, wav_file, retry=True):\n",
    "    file_id = get_file_id_from_base64_content(base64_pcm_data)\n",
    "    feishu_json = {\n",
    "        \"config\": {\n",
    "            \"engine_type\": \"16k_auto\",\n",
    "            \"file_id\": file_id,\n",
    "            \"format\": \"pcm\",\n",
    "        },\n",
    "        \"speech\": {\"speech\": f\"{base64_pcm_data}\"},\n",
    "    }\n",
    "\n",
    "    text = requests.post(\n",
    "        \"https://open.feishu.cn/open-apis/speech_to_text/v1/speech/file_recognize\",\n",
    "        json=feishu_json,\n",
    "        headers=feishu_headers_with_token,\n",
    "    ).text\n",
    "    logging.info(f\"飞书text:{text}\")\n",
    "    try:\n",
    "        text = json.loads(text)\n",
    "        return text[\"data\"][\"recognition_text\"]\n",
    "    except Exception as e:\n",
    "        logging.info(f\"调用飞书接口错误wav_file:{wav_file}, 接口返回:{text}, 异常信息:{e}\")\n",
    "        if retry:\n",
    "            logging.warning(\"20s后重试1次:\")\n",
    "            time.sleep(20)\n",
    "            return recognize_feishu_api_base64_content(\n",
    "                base64_pcm_data=base64_pcm_data, wav_file=wav_file, retry=False\n",
    "            )\n",
    "        else:\n",
    "            global failed_wav_files\n",
    "            dump_failed_json_to_file(feishu_json, file_id)\n",
    "            failed_wav_files['wav_file']=file_id\n",
    "            logging.error(f\"不再重试:{retry}\")\n",
    "        return text\n",
    "\n",
    "\n",
    "def is_feishu504_error(api_text):\n",
    "    return \"504 Gateway Time-out\" in api_text\n",
    "\n",
    "\n",
    "def file_recognize_feishu_api(wav_file):\n",
    "    # 先切分成2分钟一段：\n",
    "    sub_files = split_wav_file(wav_file)\n",
    "\n",
    "    if sub_files is None or len(sub_files) < 0:\n",
    "        logging.info(f\"切分失败：{wav_file}\")\n",
    "        return\n",
    "    if len(sub_files) > 1:\n",
    "        logging.info(f\"切分成了多个小文件：{','.join(sub_files)}\")\n",
    "    all_text = []\n",
    "    for file in sub_files:\n",
    "        base64_pcm_data = get_base64encoded_content_of_wav(wav_file)\n",
    "        logging.info(f\"wav_file:{file}, base64_pcm_data: {base64_pcm_data[-50:]}\")\n",
    "        all_text.append(\n",
    "            recognize_feishu_api_base64_content(\n",
    "                base64_pcm_data=base64_pcm_data, wav_file=file\n",
    "            )\n",
    "        )\n",
    "    return \"\".join(all_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取ODPS数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordurl_df=get_odps_sql_result_as_df(f\"\"\"\n",
    "SELECT  *,DATEDIFF(CAST(endtime AS TIMESTAMP),CAST(createtime AS TIMESTAMP),'ss') communication_time_in_seconds\n",
    "FROM    (\n",
    "            SELECT  JSON_TUPLE(body,\"eventtype\",\"sessionid\",\"direction\",\"createtime\",\"endtime\",\"connectionbeginetime\",\"connectionendtime\",\"from\",\"to\",\"user\",\"category\",\"staffid\",\"staffname\",\"status\",\"visittimes\",\"duration\",\"evaluation\",\"recordurl\",\"overflowFrom\",\"shuntGroupName\",\"ivrPath\",\"mobileArea\",\"waitDuration\",\"ringDuration\",\"sessionIdFrom\",\"firstEndDirection\") AS (\"eventtype\",\"sessionid\",\"direction\",\"createtime\",\"endtime\",\"connectionbeginetime\",\"connectionendtime\",\"from\",\"to\",\"user\",\"category\",\"staffid\",\"staffname\",\"status\",\"visittimes\",\"duration\",\"evaluation\",\"recordurl\",\"overflowFrom\",\"shuntGroupName\",\"ivrPath\",\"mobileArea\",\"waitDuration\",\"ringDuration\",\"sessionIdFrom\",\"firstEndDirection\")\n",
    "            FROM    summerfarm_tech.ods_qiyu_call_log_di\n",
    "            WHERE   ds = '{ds_to_run}'\n",
    "            AND     GET_JSON_OBJECT(body,'$.eventtype') = '5'\n",
    "        ) \n",
    "WHERE   recordurl LIKE 'https://hzxmkjyxgs7.%';\"\"\")\n",
    "\n",
    "logging.info(f\"数据量大小:{len(recordurl_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "\n",
    "def download_wav_file(url, sessionid, communication_time_in_seconds=0):\n",
    "    # Send a request to the URL\n",
    "    if communication_time_in_seconds<=30:\n",
    "        logging.info(f\"通话时长过短，不需下载语音文件:{url}, session:{sessionid}, 通话时长:{communication_time_in_seconds}s\")\n",
    "        return\n",
    "    logging.info(f\"下载语音文件:{url}, session:{sessionid}\")\n",
    "    file_name = os.path.basename(url)\n",
    "    response = requests.get(url)\n",
    "    local_file = f\"{DATA_PATH}/{sessionid}_{file_name}\"\n",
    "    if os.path.exists(local_file):\n",
    "        logging.info(f\"The file {local_file} already exists.\")\n",
    "        return\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Open a file in binary mode to write the content\n",
    "        with open(local_file, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        logging.info(f\"File {file_name} downloaded successfully.\")\n",
    "    else:\n",
    "        logging.info(\"Failed to download the file.\")\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    futures = [\n",
    "        executor.submit(download_wav_file, row[\"recordurl\"], row[\"sessionid\"], row['communication_time_in_seconds'])\n",
    "        for index, row in recordurl_df.iterrows()\n",
    "    ]\n",
    "    concurrent.futures.wait(futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 请求azure进行语音分析，还原对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the base64 encoding library.\n",
    "import base64\n",
    "\n",
    "proxy_object = {\"http\": \"http://127.0.0.1:8001\", \"https\": \"http://127.0.0.1:8001\"}\n",
    "\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# gets the API Key from environment variable AZURE_OPENAI_API_KEY\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"2023-07-01-preview\",\n",
    "    azure_endpoint=\"https://xm-ai.openai.azure.com\",\n",
    "    api_key=args.AZURE_API_KEY,\n",
    ")\n",
    "\n",
    "client_gpt4o = AzureOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://xm-ai-us2.openai.azure.com\",\n",
    "    api_key=args.AZURE_GPT4O_API_KEY,\n",
    ")\n",
    "\n",
    "\n",
    "def call_azure_openai(content=\"\", command=\"\", retrying=1, is_gpt4o=False) -> str:\n",
    "    if retrying < 0:\n",
    "        return \"超过了最大重试次数\", False\n",
    "    completion = None\n",
    "    ## gpt3.5:  gpt-35-turbo-16k,\n",
    "    ## got4o:   gpt-4o\n",
    "    model = \"gpt-35-turbo-16k\"\n",
    "    client_to_use = client\n",
    "    if is_gpt4o:\n",
    "        logging.info(f\"using GPT-4o...:{command}\")\n",
    "        model = \"gpt-4o\"\n",
    "        client_to_use = client_gpt4o\n",
    "    try:\n",
    "        completion = client_to_use.chat.completions.create(\n",
    "            model=model,\n",
    "            temperature=0.1,\n",
    "            max_tokens=4095,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": f\"你是一个资深的销售主管。\\n**请你根据用户给的内容分析销售员和客户之间的对话。**\\n通常来说对话都是销售员发起的。\\n{command}\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"```{content}```\",\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "        response = completion.choices[0].message.content\n",
    "        if (\n",
    "            len(completion.choices) <= 0\n",
    "            or f\"{completion.choices[0].finish_reason}\" == \"content_filter\"\n",
    "        ):\n",
    "            return f\"azure过滤了本次请求:{completion.choices[0].to_dict()}\", False\n",
    "        if response is None:\n",
    "            logging.info(f\"azure API返回了异常:{completion.to_dict()}\")\n",
    "            return call_azure_openai(\n",
    "                content=content,\n",
    "                command=command,\n",
    "                retrying=retrying - 1,\n",
    "                is_gpt4o=is_gpt4o,\n",
    "            )\n",
    "        return response, True\n",
    "    except Exception as e:\n",
    "        logging.info(f\"请求azure接口报错了:{e}\\n content:{content}, completion:{completion}\")\n",
    "        if retrying <= 0 or \"Error code: 400\" in f\"{e}\":\n",
    "            return f\"{e}\", False\n",
    "    logging.info(f\"重试中...{retrying}, content:{content}\")\n",
    "    return call_azure_openai(\n",
    "        content=content, command=command, retrying=retrying - 1, is_gpt4o=is_gpt4o\n",
    "    )\n",
    "\n",
    "\n",
    "commands = [\n",
    "    {\n",
    "        \"name\": \"对话总结\",\n",
    "        \"text\": \"以下文本是我公司销售员/客服和客户之间的通话录音。请你总结对话的内容，提炼出核心事件\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"客情判断\",\n",
    "        \"text\": \"以下文本是我公司销售员/客服和客户之间的通话录音。请你分析客户对我司的评价是正面的，还是负面的，并给出分析依据\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"销售达成情况\",\n",
    "        \"text\": \"请你分析销售员与客户之间的对话内容，并判断我们的销售员是否达成了销售目标。如果客户问到了具体价格且表示认可，也算是销售成功。\\n如果销售达成，则列出销售成功的商品名字。否则列出销售失败的原因\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "def call_ai_api_to_get_insigns(feishu_text):\n",
    "    result = {}\n",
    "    dialog, is_ok = call_azure_openai(\n",
    "        is_gpt4o=True,\n",
    "        content=feishu_text,\n",
    "        command=\"\"\"以下文本是我司销售员和客户之间的对话。\n",
    "请你对对话内容进行还原，区分哪些内容是销售员说的、哪些是客户说的。\n",
    "将销售员说的内容用\"销售员：\"表示。将客户说的内容用\"客户：\"表示。\n",
    "\n",
    "## 请注意：\n",
    "- **请你完全基于我给出的内容进行还原，未出现的对话内容不要出现在你的结果中。**\n",
    "- **如果对话内容过于简短，比如少于50字，请你直接回复“对话内容过于简短，无需还原”**\"\"\",\n",
    "    )\n",
    "    result[\"对话还原\"] = dialog\n",
    "    if not is_ok:\n",
    "        logging.info(\"失败:\", dialog)\n",
    "        return result\n",
    "    if dialog is None or len(dialog) <= 30 or \"对话内容过于简短，无需还原\" in dialog:\n",
    "        result[\"error\"] = (\n",
    "            f\"AI返回的对话内容太短了，疑似出错了:{dialog}, 飞书文本:{feishu_text}\"\n",
    "        )\n",
    "        logging.error(f\"{result}\")\n",
    "        return result\n",
    "    for command in commands:\n",
    "        result[command[\"name\"]], is_ok = call_azure_openai(dialog, command[\"text\"])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feishu_file_recognize_result_for_row(row_dict):\n",
    "    try:\n",
    "        row = row_dict\n",
    "        communication_time_in_seconds = row[\"communication_time_in_seconds\"]\n",
    "        if communication_time_in_seconds <= 30:\n",
    "            ignored = f\"通话时长不到30s:{communication_time_in_seconds}s,{row['user']}, {row['sessionid']}\"\n",
    "            row[\"feishu_file_recognize_result\"] = ignored\n",
    "            return ignored\n",
    "        logging.info(f\"sessionid:{row['sessionid']}, recordurl:{row['recordurl']}\")\n",
    "        text = \"\"\n",
    "        text = file_recognize_feishu_api(\n",
    "            f\"{DATA_PATH}/{row['sessionid']}_{os.path.basename(row['recordurl'])}\"\n",
    "        )\n",
    "        logging.info(f\"{row['sessionid']} 的文本:{text}\")\n",
    "        row[\"feishu_file_recognize_result\"] = text\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        row[\"feishu_file_recognize_result\"] = f\"错误:{e}\"\n",
    "        return \"ERROR\"\n",
    "\n",
    "\n",
    "row_dict_list = [row.to_dict() for _, row in recordurl_df.iterrows()]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    # Submit tasks to the executor\n",
    "    futures = [\n",
    "        executor.submit(get_feishu_file_recognize_result_for_row, row_dict)\n",
    "        for row_dict in row_dict_list\n",
    "    ]\n",
    "    concurrent.futures.wait(futures)\n",
    "\n",
    "recordurl_with_text_df = pd.DataFrame(row_dict_list)\n",
    "\n",
    "recordurl_with_text_df[[\"sessionid\", \"user\", \"staffname\", \"feishu_file_recognize_result\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 写入ODPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gemini_result(row):\n",
    "    feishu_file_recognize_result = row[\"feishu_file_recognize_result\"]\n",
    "    logging.info(f\"feishu_file_recognize_result: {feishu_file_recognize_result}\")\n",
    "    if (\n",
    "        \"504 Gateway Time-out\" in f\"{feishu_file_recognize_result}\"\n",
    "        or \"通话时长不到30s\" in f\"{feishu_file_recognize_result}\"\n",
    "    ):\n",
    "        logging.info(f\"飞书文本异常：{feishu_file_recognize_result}\")\n",
    "        return feishu_file_recognize_result\n",
    "\n",
    "    logging.info(\n",
    "        f\"sessionid:{row['sessionid']}, feishu_file_recognize_result:{feishu_file_recognize_result}\"\n",
    "    )\n",
    "    ai_response = call_ai_api_to_get_insigns(feishu_file_recognize_result)\n",
    "    logging.info(f\"{row['sessionid']} API分析:\\n{ai_response}\")\n",
    "    return f\"{ai_response}\"\n",
    "\n",
    "\n",
    "recordurl_with_text_df.to_csv(\n",
    "    f\"{DATA_PATH}/qiyu_records_with_feishu_recognize_result.csv\", index=False\n",
    ")\n",
    "# 先保存一份仅仅包含飞书语音识别的结果\n",
    "write_pandas_df_into_odps_overwrite(\n",
    "    recordurl_with_text_df.astype(str),\n",
    "    \"summerfarm_ds.crm_qiyu_call_feishu_result_raw_di\",\n",
    "    f\"ds={ds_to_run}\",\n",
    ")\n",
    "\n",
    "if \"true\" == CALL_AI_SERVICE:\n",
    "    recordurl_with_text_df[\"gemini_result\"] = recordurl_with_text_df.apply(\n",
    "        get_gemini_result, axis=1\n",
    "    )\n",
    "    recordurl_with_text_df = recordurl_with_text_df.astype(str)\n",
    "    recordurl_with_text_df.to_csv(\n",
    "        f\"{DATA_PATH}/qiyu_records_with_ai_result.csv\", index=False\n",
    "    )\n",
    "    write_pandas_df_into_odps_overwrite(\n",
    "        recordurl_with_text_df,\n",
    "        \"summerfarm_ds.crm_qiyu_call_analytics_raw_v2_di\",\n",
    "        f\"ds={ds_to_run}\",\n",
    "    )\n",
    "else:\n",
    "    logging.warn(\"将不请求AI服务！！\")\n",
    "\n",
    "days_15d=(datetime.now()-timedelta(15)).strftime(\"%Y%m%d\")\n",
    "df=get_odps_sql_result_as_df(f\"select ds,count(1) cnt from summerfarm_ds.crm_qiyu_call_feishu_result_raw_di where ds>='{days_15d}' group by ds order by ds\")\n",
    "df.head(20)\n",
    "\n",
    "logging.info(f\"成功了！\\n>>>>>>>>>>>>\\n失败的wav文件列表:{failed_wav_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
